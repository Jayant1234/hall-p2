{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"C:\\\\Users\\\\Jayant\\\\Pictures\\\\wallpapers\\\\page.jpg\",cv.IMREAD_GRAYSCALE)\n",
    "print(type(img))\n",
    "print(type(img.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing an image\n",
    "resized= cv.resize(img, (250,250))\n",
    "# cv2.imshow(\"Larry Page\", resized)\n",
    "# cv2.waitKey(0)\n",
    "lum_img = img[:,:]\n",
    "#imgplot = plt.imshow(resized,cmap=\"hot\")\n",
    "#resizing the already resized image\n",
    "resized_2=cv.resize(resized, (650,650))\n",
    "imgplot = plt.imshow(resized_2,cmap=\"hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_names():\n",
    "    '''\n",
    "    Reads train.txt file from dataset folder and creates a list with all lines in train.txt file.\n",
    "    The lines in train.txt contain ids for each individual folder containing respective frames.\n",
    "    '''\n",
    "    f = open(\"../dataset/train.txt\", \"r\")\n",
    "    train_names=f.read().splitlines()\n",
    "    print(len(train_names))\n",
    "    return train_names\n",
    "\n",
    "\n",
    "\n",
    "def get_test_names(): \n",
    "    '''\n",
    "    Reads test.txt file from dataset folder and creates a list with all lines in train.txt file.\n",
    "    The lines in train.txt contain ids for each individual folder containing respective frames.\n",
    "    '''\n",
    "    f = open(\"../dataset/test.txt\", \"r\")\n",
    "    test_names=f.read().splitlines()\n",
    "    print(len(test_names))\n",
    "    return test_names\n",
    "\n",
    "train_names=get_train_names()\n",
    "test_names=get_test_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_video_dictionary(train_names): \n",
    "    \"\"\"\n",
    "    creates a dictionary of dictionary with following structure\n",
    "    dict_videos --> key = train filename , value = dict_image --> key = frame no. of images, value = image of celia\n",
    "    ie first dictonary size is 211 and every dictionary inside 211 dictionaries have size 100. \n",
    "    And dictionaries with size 100 contain the images by frames. \n",
    "    \"\"\"\n",
    "    length=0 # to check the length of total dataset\n",
    "    dict_videos= {}\n",
    "    for name in train_names: \n",
    "        dict_images={}    \n",
    "        for i in range(len(os.listdir(\"../dataset/data/\"+name))): \n",
    "            dict_images[str(i)]= cv.imread(\"../dataset/data/\"+name+\"/frame00\"+\"{:02d}\".format(i)+\".png\",cv.IMREAD_GRAYSCALE)\n",
    "            \n",
    "        length=length+len(dict_images)\n",
    "        dict_videos[name]=dict_images\n",
    "    #what I am doing here is error checking, can do this professionally also..do it after experiments..\n",
    "    print(\"Length of total dataset, should be 21100 :\"+ str(length))    \n",
    "    return dict_videos\n",
    "\n",
    "#dict_videos_train =data_video_dictionary(train_names)\n",
    "dict_videos_test =data_video_dictionary(test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_dictionary(train_names): \n",
    "    \"\"\"\n",
    "    creates a dictionary of masks with key as train_name and value as the image ie the mask. \n",
    "    \"\"\"\n",
    "    masks={}\n",
    "    for name in train_names:\n",
    "        masks[name]=cv.imread(\"../dataset/masks/\"+name+\".png\",cv.IMREAD_GRAYSCALE)\n",
    "        \n",
    "    return masks\n",
    "\n",
    "mask=get_mask_dictionary(train_names)\n",
    "#imgplot = plt.imshow(mask[train_names[0]],cmap=\"hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operation_on_images(dict_videos,train_names,image_name=\"frame00\"): \n",
    "    result={}\n",
    "    for name in train_names:\n",
    "        dict_image= dict_videos[name]\n",
    "        for i in range(len(dict_image)): \n",
    "            image=dict_image[str(i)]\n",
    "            #print(str(i)+\":\"+str(type(dict_image[str(i)])))\n",
    "            #how can an abstraction be created such that I can name things based on result here using\n",
    "            #just above generic methods?\n",
    "        #result action.     \n",
    "    return result\n",
    "operation_on_images(dict_videos_train,train_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_videos_train)\n",
    "len(dict_videos_train[train_names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find shortest x and y for images in dataset? \n",
    "#can resize to a generic normal dimension also.. but lets try this first.\n",
    "\n",
    "def operation_on_images_smallest_dimensions(dict_videos,train_names): \n",
    "    x=10000\n",
    "    y=10000\n",
    "    for name in train_names:\n",
    "        dict_image= dict_videos[name]\n",
    "        for i in range(len(dict_image)): \n",
    "            image_name= str(i)\n",
    "            image=dict_image[image_name]\n",
    "            image_dimension=image.shape\n",
    "            if image_dimension[0]<x : \n",
    "                x=image_dimension[0]\n",
    "            if image_dimension[1]<y : \n",
    "                y=image_dimension[0]\n",
    "        #result action.     \n",
    "    return [x,y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_xy= operation_on_images_smallest_dimensions(dict_videos,train_names)\n",
    "print(\"smallest dimensions are, for x=\"+str(list_xy[0])+\" and for y=\"+str(list_xy[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing every image to 128*128 \n",
    "\n",
    "def operation_on_images_resizing(dict_videos,train_names,dimensions=[128,128]): \n",
    "    dict_videos_resized = copy.deepcopy(dict_videos)\n",
    "    for name in train_names:\n",
    "        dict_image= dict_videos_resized[name]\n",
    "        for i in range(len(dict_image)): \n",
    "            image_name= str(i)\n",
    "            image=dict_image[image_name]\n",
    "            new_image=cv.resize(image, (128,128)) #this hard coded value need to be met with x and y results. \n",
    "            dict_image[image_name]=new_image\n",
    "        #result action.     \n",
    "    return dict_videos_resized\n",
    "\n",
    "dict_videos_resized= operation_on_images_resizing(dict_videos_test,test_names)\n",
    "#takes 5 minutes to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_videos_resized['4bad52d5ef5f68e87523ba40aa870494a63c318da7ec7609e486e62f7f7a25e8'][str(int(0))].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image operations are taking damn too long!! the resizing especially!!\n",
    "#next step is fluctuation variation\n",
    "#play with image gradients,\n",
    "#play with adding frame images and doing something with them \n",
    "# then create pipeline to train on unet\n",
    "# then create pipeline to train on some other model which is readily available.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing a few things \n",
    "#https://stackoverflow.com/questions/17291455/how-to-get-an-average-picture-from-100-pictures-using-pil\n",
    "imarr=np.array(img,dtype=np.float)\n",
    "imgplot = plt.imshow(imarr,cmap=\"hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fluctuation variation :  my intuition is that , on all pixels in 100 images.. we have 128*128 distributions \n",
    "#and we can calculate variance in every pixel of all 100 frames and use that to predict labels first ??\n",
    "# can define variance_on_images_with_same dimension and also on variable dimensions ie without resizing..\n",
    "def variance_on_images_resized(dict_videos,train_names,dimensions=(128,128),hop=1,scale=1): \n",
    "    dict_videos_mean={}\n",
    "    dict_videos_variance={}\n",
    "    for name in train_names:\n",
    "        dict_image= dict_videos[name]\n",
    "        arr=np.zeros(dimensions,np.float)\n",
    "        N_1=len(list(range(0,len(dict_image),hop)))\n",
    "        N_2=len(list(range(0,len(dict_image))))\n",
    "        #calculating mean of an image. \n",
    "        for i in range(0,len(dict_image),hop): \n",
    "            image=dict_image[str(i)]\n",
    "            imarr=np.array(image,dtype=np.float)\n",
    "            arr=arr+imarr/N_1\n",
    "        image_mean=np.array(np.round(arr),dtype=np.uint8)\n",
    "        dict_videos_mean[name]=image_mean #for later use, can send as results.\n",
    "        varr=np.zeros(dimensions,np.float)\n",
    "        for i in range(0,len(dict_image),hop): \n",
    "            #using arr because its an image_mean in float type\n",
    "            image=dict_image[str(i)]\n",
    "            imarr=np.array(image,dtype=np.float)\n",
    "            varr=varr+ (scale*(imarr-arr)**2)/N_1\n",
    "        variance_image =np.array(np.round(varr),dtype=np.uint8)\n",
    "        dict_videos_variance[name]=variance_image\n",
    "        #calculating square of X-mean\n",
    "        #result action.     \n",
    "    return dict_videos_mean,dict_videos_variance\n",
    "#hop of 15 is used because Ciliary motion does 5-6 oscillations in 1 frame..so, 15*6 will capture those oscillations\n",
    "dict_videos_mean,dict_videos_variance=variance_on_images_resized(dict_videos_resized,test_names,hop=4,scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_on_images_original(dict_videos,train_names,hop=1,scale=1): \n",
    "    dict_videos_mean={}\n",
    "    dict_videos_variance={}\n",
    "    for name in train_names:\n",
    "        dict_image= dict_videos[name]\n",
    "        arr=np.zeros(dict_image[str(0)].shape,np.float)\n",
    "        N_1=len(list(range(0,len(dict_image),hop)))\n",
    "        N_2=len(list(range(0,len(dict_image))))\n",
    "        #calculating mean of an image. \n",
    "        for i in range(0,len(dict_image),hop): \n",
    "            image=dict_image[str(i)]\n",
    "            imarr=np.array(image,dtype=np.float)\n",
    "            arr=arr+imarr/N_1\n",
    "        image_mean=np.array(np.round(arr),dtype=np.uint8)\n",
    "        dict_videos_mean[name]=image_mean #for later use, can send as results.\n",
    "        varr=np.zeros(dict_image[str(0)].shape,np.float)\n",
    "        for i in range(0,len(dict_image),hop): \n",
    "            #using arr because its an image_mean in float type\n",
    "            image=dict_image[str(i)]\n",
    "            imarr=np.array(image,dtype=np.float)\n",
    "            varr=varr+ (scale*(imarr-arr)**2)/N_1\n",
    "        variance_image =np.array(np.round(varr),dtype=np.uint8)\n",
    "        dict_videos_variance[name]=variance_image\n",
    "        #calculating square of X-mean\n",
    "        #result action.     \n",
    "    return dict_videos_mean,dict_videos_variance\n",
    "#hop of 15 is used because Ciliary motion does 5-6 oscillations in 1 frame..so, 15*6 will capture those oscillations\n",
    "dict_videos_mean,dict_videos_variance=variance_on_images_original(dict_videos_test,test_names,hop=1,scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(dict_videos_variance[test_names[50]],cmap=\"hot\")\n",
    "# best to input in a CNN if possible is hop=4, scale =2 variation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above method..how to threshold?? and create masks??\n",
    "#important thresholding link :-https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html\n",
    "trainer=train_names[0]\n",
    "threshold=20 #another parameter to tune now..\n",
    "image_meaned=dict_videos_mean[trainer]\n",
    "\n",
    "image_variance=dict_videos_variance[trainer]\n",
    "\n",
    "ret,thresh1 = cv.threshold(image_variance,threshold,255,cv.THRESH_BINARY)\n",
    "\n",
    "th3 = cv.adaptiveThreshold(image_variance,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2)\n",
    "\n",
    "ret3,th4 = cv.threshold(image_variance,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "blur = cv.GaussianBlur(image_variance,(5,5),255)\n",
    "ret3,th5 = cv.threshold(blur,threshold,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "images=[image_meaned,image_variance,thresh1,th3,th4,th5]\n",
    "titles = ['Mean Image','Variance Image','Global Thresholding (v=10)',\n",
    "          'adaptive gaussian thresholding',\"Otsu's Thresholding\",\"Otsu's Thresholding with gaussian filtering\"]\n",
    "f, axarr = plt.subplots(2,3)\n",
    "axarr[0,0].imshow(images[0])\n",
    "axarr[0,1].imshow(images[1])\n",
    "axarr[0,2].imshow(images[2])\n",
    "axarr[1,0].imshow(images[3])\n",
    "axarr[1,1].imshow(images[4])\n",
    "axarr[1,2].imshow(images[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets threshold and create masks from it and compare with a train_set accuracy.. and then if its better than 25% ,\n",
    "#do the same for test. and then do unet.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresold_variance(dict_videos_variance,threshold=10):\n",
    "    dict_threshold={} \n",
    "    for name in test_names: \n",
    "        ret3,th5 = cv.threshold(dict_videos_variance[name],threshold,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "        dict_threshold[name]= th5\n",
    "    return dict_threshold\n",
    "\n",
    "def create_masks(dict_threshold): \n",
    "    for name in test_names: \n",
    "        dict_threshold[name][dict_threshold[name]!= 255 ] = 0\n",
    "        dict_threshold[name][dict_threshold[name]== 255 ] = 2  \n",
    "    return dict_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks=create_masks(thresold_variance(dict_videos_variance,5))\n",
    "#imgplot = plt.imshow(masks[test_names[50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create masks.pngs for variance...\n",
    "def write_masks(masks,test_names): \n",
    "    result =0\n",
    "    for name in test_names: \n",
    "        if not os.path.exists('../dataset/test_masks'):\n",
    "            os.makedirs('../dataset/test_masks')\n",
    "        cv.imwrite(\"../dataset/test_masks/\"+name+\".png\",masks[name])\n",
    "        result=result+1\n",
    "write_masks(masks,test_names)\n",
    "#getting 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "#getting zero, doing something wrong maybe masks are not right..This is the worng part.. use tar cvf p2.tar *.png in the test_masks folder..\n",
    "def make_tarfile(output_filename='p2sub.tar', source_dir='../dataset/test_masks'):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "        tar.close()\n",
    "        #make tar of all images instead... of this...\n",
    "make_tarfile()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#still giving zero accuracy for variance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
